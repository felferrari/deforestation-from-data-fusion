{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2770d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c56f2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ops.ops import load_json, save_json\n",
    "import ee\n",
    "#import geemap\n",
    "import fiona\n",
    "import time\n",
    "#import json\n",
    "import os\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95f8323d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=UVA9bbDGKDYd_N5pYnE_Js__pL0jGtQj2kPJpWI9dyI&tc=obgDGJTdy4NfjcVngoH26k4rC3J-YqSnbAMXBt0_gHI&cc=bZqYqW69Bi-Yvy4pAM6qEEwIs1gegl9421_s_lxHtlQ>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=UVA9bbDGKDYd_N5pYnE_Js__pL0jGtQj2kPJpWI9dyI&tc=obgDGJTdy4NfjcVngoH26k4rC3J-YqSnbAMXBt0_gHI&cc=bZqYqW69Bi-Yvy4pAM6qEEwIs1gegl9421_s_lxHtlQ</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you\n",
       "        should paste in the box below</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter verification code: 4/1AX4XfWgY2nXFcJAq4lw59O94Q2-WP0N5XHNwf2il1cTSnOqMAYJSJqm0_bs\n",
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc4b859a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704862dd18b942f1829938021bc0c8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-23, -45], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Tâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map = geemap.Map(center=(-23, -45), zoom=8)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "210a9c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = load_json(os.path.join('conf', 'paths.json'))\n",
    "shp = load_json(os.path.join('conf', 'shp.json'))\n",
    "shp_path = paths['shp']\n",
    "max_cloud_cover = 95\n",
    "max_thin_cirrus = 0.1\n",
    "delta_days = 10\n",
    "meta_path = os.path.join('img', 'metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f3230ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file = shp['shp_base']\n",
    "grid_source = os.path.join(shp_path, f'{source_file}.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "580f4f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_fn(date):\n",
    "    def diff_date(image):\n",
    "        return image.set(\n",
    "        'dateDist',\n",
    "        ee.Number(image.get('system:time_start')).subtract(datetime.datetime.strptime(date, '%Y-%m-%d').timestamp()*1000).abs()\n",
    "      )\n",
    "    return diff_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f69e29e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_date(day, year, img_coll):\n",
    "    date_i = datetime.datetime.strptime(f'{year}{day}', '%y%j').strftime('%Y-%m-%d')\n",
    "    date_f = datetime.datetime.strptime(f'{year}{day+1}', '%y%j').strftime('%Y-%m-%d')\n",
    "\n",
    "    img_coll_t = img_coll.filterBounds(roi).filterDate(date_i, date_f)\n",
    "    #print(d19_t)\n",
    "    #print(opt_col_2019_t.size().getInfo())\n",
    "    if img_coll_t.size().getInfo() > 0:\n",
    "        min_mask = img_coll_t.mean().select('B2').mask().reduceRegion(ee.Reducer.min(), roi, 10).getInfo()['B2']\n",
    "        if min_mask == 1:\n",
    "            return False\n",
    "        if min_mask == 0:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76db98da",
   "metadata": {},
   "source": [
    "## Evaluate L-2A images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "071aacb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7750ddca381c45afbf1e5d95054fd433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tiles evaluated:   0%|          | 0/255 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dest_file = shp['shp_imgs_l2']\n",
    "grid_dest = os.path.join(shp_path, f'{dest_file}.shp')\n",
    "\n",
    "with fiona.open(grid_source) as grid:\n",
    "    source_driver = grid.driver\n",
    "    source_crs = grid.crs\n",
    "    source_schema = grid.schema\n",
    "    \n",
    "    #adding new shapefile columns\n",
    "    source_schema['properties'].update({'cloud_2019':'float:24.15'})\n",
    "    source_schema['properties'].update({'cloud_2020':'float:24.15'})\n",
    "    source_schema['properties'].update({'cloud_max':'float:24.15'})\n",
    "    source_schema['properties'].update({'opt_2019':'str:254'})\n",
    "    source_schema['properties'].update({'opt_2020':'str:254'})\n",
    "    source_schema['properties'].update({'sar_2019':'str:254'})\n",
    "    source_schema['properties'].update({'sar_2020':'str:254'})\n",
    "    source_schema['properties'].update({'crs':'str:254'})\n",
    "    \n",
    "    with fiona.open(grid_dest, 'w', driver=source_driver, crs=source_crs, schema=source_schema) as dest:\n",
    "        \n",
    "        for feat in tqdm_notebook(grid, desc = 'Tiles evaluated'):\n",
    "            roi = ee.Geometry(feat['geometry'])\n",
    "            feat_id = int(feat['properties']['id'])\n",
    "\n",
    "            d19 = int(feat['properties']['jday_2019'])\n",
    "            d20 = int(feat['properties']['jday_2020'])\n",
    "            d19_1 = d19-delta_days\n",
    "            d19_2 = d19+delta_days\n",
    "            d20_1 = d20-delta_days\n",
    "            d20_2 = d20+delta_days\n",
    "\n",
    "            d19 = datetime.datetime.strptime(f'19{d19}', '%y%j').strftime('%Y-%m-%d')\n",
    "            d20 = datetime.datetime.strptime(f'20{d20}', '%y%j').strftime('%Y-%m-%d')\n",
    "            d19_1 = datetime.datetime.strptime(f'19{d19_1}', '%y%j').strftime('%Y-%m-%d')\n",
    "            d19_2 = datetime.datetime.strptime(f'19{d19_2}', '%y%j').strftime('%Y-%m-%d')\n",
    "            d20_1 = datetime.datetime.strptime(f'20{d20_1}', '%y%j').strftime('%Y-%m-%d')\n",
    "            d20_2 = datetime.datetime.strptime(f'20{d20_2}', '%y%j').strftime('%Y-%m-%d')\n",
    "\n",
    "            opt_col_2019 = ee.ImageCollection('COPERNICUS/S2_SR').filterDate(d19_1, d19_2)\n",
    "            opt_col_2020 = ee.ImageCollection('COPERNICUS/S2_SR').filterDate(d20_1, d20_2)\n",
    "            sar_col_2019 = ee.ImageCollection('COPERNICUS/S1_GRD').filterDate(d19_1, d19_2)\n",
    "            sar_col_2020 = ee.ImageCollection('COPERNICUS/S1_GRD').filterDate(d20_1, d20_2)\n",
    "            \n",
    "            opt_col_2019 = opt_col_2019.map(prep_fn(d19))\n",
    "            opt_col_2020 = opt_col_2020.map(prep_fn(d20))\n",
    "            sar_col_2019 = sar_col_2019.map(prep_fn(d19))\n",
    "            sar_col_2020 = sar_col_2020.map(prep_fn(d20))\n",
    "\n",
    "            #print(f'\\n\\nlocating images from grid {feat_id}...')\n",
    "\n",
    "            opt_2019 = opt_col_2019.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',max_cloud_cover))\n",
    "            #opt_2019 = opt_col_2019.filter(ee.Filter.lt('THIN_CIRRUS_PERCENTAGE',max_thin_cirrus))\n",
    "            opt_2019 = opt_2019.filterBounds(roi)\n",
    "            opt_2019 = opt_2019.filter(ee.Filter.contains('.geo', roi))\n",
    "\n",
    "            opt_2020 = opt_col_2020.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',max_cloud_cover))\n",
    "            #opt_2020 = opt_col_2020.filter(ee.Filter.lt('THIN_CIRRUS_PERCENTAGE',max_thin_cirrus))\n",
    "            opt_2020 = opt_2020.filterBounds(roi)\n",
    "            opt_2020 = opt_2020.filter(ee.Filter.contains('.geo', roi))\n",
    "\n",
    "            sar_2019 = sar_col_2019.filterBounds(roi)\n",
    "            sar_2019 = sar_2019.filter(ee.Filter.contains('.geo', roi))\n",
    "            sar_2020 = sar_col_2020.filterBounds(roi)\n",
    "            sar_2020 = sar_2020.filter(ee.Filter.contains('.geo', roi))\n",
    "            #print(f'counting images from grid {feat_id}...')\n",
    "\n",
    "            n_opt_2019 = opt_2019.size().getInfo()\n",
    "            n_opt_2020 = opt_2020.size().getInfo()\n",
    "            n_sar_2019 = sar_2019.size().getInfo()\n",
    "            n_sar_2020 = sar_2020.size().getInfo()\n",
    "\n",
    "            #print(f'Number of images from grid {feat_id}: OPT_2019:{n_opt_2019} | OPT_2020:{n_opt_2020} | SAR_2019:{n_sar_2019} | SAR_2020:{n_sar_2020} ')\n",
    "            \n",
    "            if n_opt_2019 == 0 or n_opt_2020 == 0 or n_sar_2019 == 0 or n_sar_2020 == 0:\n",
    "                continue\n",
    "            \n",
    "            opt_2019 = opt_2019.sort('dateDist').first()\n",
    "            opt_2019_pm = opt_2019.select(['MSK_CLDPRB']).clip(roi)\n",
    "            \n",
    "            opt_2020 = opt_2020.sort('dateDist').first()\n",
    "            opt_2020_pm = opt_2020.select(['MSK_CLDPRB']).clip(roi)\n",
    "            max_pm = opt_2019_pm.max(opt_2020_pm)\n",
    "            \n",
    "            sar_2019 = sar_2019.sort('dateDist').first()\n",
    "            sar_2020 = sar_2020.sort('dateDist').first()\n",
    "\n",
    "            mean_opt_2019 =  opt_2019_pm.reduceRegion(ee.Reducer.mean()).getInfo()['MSK_CLDPRB']\n",
    "            mean_opt_2020 =  opt_2020_pm.reduceRegion(ee.Reducer.mean()).getInfo()['MSK_CLDPRB']\n",
    "            max_opt =  max_pm.reduceRegion(ee.Reducer.mean()).getInfo()['MSK_CLDPRB']\n",
    "\n",
    "            feat['properties']['cloud_2019'] = mean_opt_2019\n",
    "            feat['properties']['cloud_2020'] = mean_opt_2020\n",
    "            feat['properties']['cloud_max'] = max_opt\n",
    "            feat['properties']['opt_2019'] = opt_2019.getInfo()['id']\n",
    "            feat['properties']['opt_2020'] = opt_2020.getInfo()['id']\n",
    "            feat['properties']['sar_2019'] = sar_2019.getInfo()['id']\n",
    "            feat['properties']['sar_2020'] = sar_2020.getInfo()['id']\n",
    "            feat['properties']['crs'] = opt_2019.getInfo()['bands'][1]['crs']\n",
    "            \n",
    "            dest.write(feat)\n",
    "            \n",
    "            meta_opt_2019 = os.path.join(meta_path, f'{feat_id}_opt_2019.txt')\n",
    "            meta_opt_2020 = os.path.join(meta_path, f'{feat_id}_opt_2020.txt')\n",
    "            meta_sar_2019 = os.path.join(meta_path, f'{feat_id}_sar_2019.txt')\n",
    "            meta_sar_2020 = os.path.join(meta_path, f'{feat_id}_sar_2020.txt')\n",
    "            \n",
    "            save_json(opt_2019.getInfo(), meta_opt_2019)\n",
    "            save_json(opt_2020.getInfo(), meta_opt_2020)\n",
    "            save_json(sar_2019.getInfo(), meta_sar_2019)\n",
    "            save_json(sar_2020.getInfo(), meta_sar_2020)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5369fa2",
   "metadata": {},
   "source": [
    "## Evaluate L-1C images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e10cebe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86314eb09f094cea817ec058ac97283c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tiles evaluated:   0%|          | 0/255 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dest_file = shp['shp_imgs_l1']\n",
    "grid_dest = os.path.join(shp_path, f'{dest_file}.shp')\n",
    "\n",
    "with fiona.open(grid_source) as grid:\n",
    "    source_driver = grid.driver\n",
    "    source_crs = grid.crs\n",
    "    source_schema = grid.schema\n",
    "    \n",
    "    #adding new shapefile columns\n",
    "    source_schema['properties'].update({'opt_2019':'str:254'})\n",
    "    source_schema['properties'].update({'opt_2020':'str:254'})\n",
    "    source_schema['properties'].update({'sar_2019':'str:254'})\n",
    "    source_schema['properties'].update({'sar_2020':'str:254'})\n",
    "    source_schema['properties'].update({'crs':'str:254'})\n",
    "    \n",
    "    with fiona.open(grid_dest, 'w', driver=source_driver, crs=source_crs, schema=source_schema) as dest:\n",
    "        \n",
    "        for feat in tqdm_notebook(grid, desc = 'Tiles evaluated'):\n",
    "            roi = ee.Geometry(feat['geometry'])\n",
    "            feat_id = int(feat['properties']['id'])\n",
    "\n",
    "            d19 = int(feat['properties']['jday_2019'])\n",
    "            d20 = int(feat['properties']['jday_2020'])\n",
    "            d19_1 = d19-delta_days\n",
    "            d19_2 = d19+delta_days\n",
    "            d20_1 = d20-delta_days\n",
    "            d20_2 = d20+delta_days\n",
    "\n",
    "            d19 = datetime.datetime.strptime(f'19{d19}', '%y%j').strftime('%Y-%m-%d')\n",
    "            d20 = datetime.datetime.strptime(f'20{d20}', '%y%j').strftime('%Y-%m-%d')\n",
    "            d19_1 = datetime.datetime.strptime(f'19{d19_1}', '%y%j').strftime('%Y-%m-%d')\n",
    "            d19_2 = datetime.datetime.strptime(f'19{d19_2}', '%y%j').strftime('%Y-%m-%d')\n",
    "            d20_1 = datetime.datetime.strptime(f'20{d20_1}', '%y%j').strftime('%Y-%m-%d')\n",
    "            d20_2 = datetime.datetime.strptime(f'20{d20_2}', '%y%j').strftime('%Y-%m-%d')\n",
    "\n",
    "            opt_col_2019 = ee.ImageCollection('COPERNICUS/S2').filterDate(d19_1, d19_2)\n",
    "            opt_col_2020 = ee.ImageCollection('COPERNICUS/S2').filterDate(d20_1, d20_2)\n",
    "            sar_col_2019 = ee.ImageCollection('COPERNICUS/S1_GRD').filterDate(d19_1, d19_2)\n",
    "            sar_col_2020 = ee.ImageCollection('COPERNICUS/S1_GRD').filterDate(d20_1, d20_2)\n",
    "            \n",
    "            opt_col_2019 = opt_col_2019.map(prep_fn(d19))\n",
    "            opt_col_2020 = opt_col_2020.map(prep_fn(d20))\n",
    "            sar_col_2019 = sar_col_2019.map(prep_fn(d19))\n",
    "            sar_col_2020 = sar_col_2020.map(prep_fn(d20))\n",
    "\n",
    "            #print(f'\\n\\nlocating images from grid {feat_id}...')\n",
    "\n",
    "            opt_2019 = opt_col_2019.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',max_cloud_cover))\n",
    "            #opt_2019 = opt_col_2019.filter(ee.Filter.lt('THIN_CIRRUS_PERCENTAGE',max_thin_cirrus))\n",
    "            opt_2019 = opt_2019.filterBounds(roi)\n",
    "            opt_2019 = opt_2019.filter(ee.Filter.contains('.geo', roi))\n",
    "\n",
    "            opt_2020 = opt_col_2020.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',max_cloud_cover))\n",
    "            #opt_2020 = opt_col_2020.filter(ee.Filter.lt('THIN_CIRRUS_PERCENTAGE',max_thin_cirrus))\n",
    "            opt_2020 = opt_2020.filterBounds(roi)\n",
    "            opt_2020 = opt_2020.filter(ee.Filter.contains('.geo', roi))\n",
    "\n",
    "            sar_2019 = sar_col_2019.filterBounds(roi)\n",
    "            sar_2019 = sar_2019.filter(ee.Filter.contains('.geo', roi))\n",
    "            sar_2020 = sar_col_2020.filterBounds(roi)\n",
    "            sar_2020 = sar_2020.filter(ee.Filter.contains('.geo', roi))\n",
    "            #print(f'counting images from grid {feat_id}...')\n",
    "\n",
    "            n_opt_2019 = opt_2019.size().getInfo()\n",
    "            n_opt_2020 = opt_2020.size().getInfo()\n",
    "            n_sar_2019 = sar_2019.size().getInfo()\n",
    "            n_sar_2020 = sar_2020.size().getInfo()\n",
    "\n",
    "            #print(f'Number of images from grid {feat_id}: OPT_2019:{n_opt_2019} | OPT_2020:{n_opt_2020} | SAR_2019:{n_sar_2019} | SAR_2020:{n_sar_2020} ')\n",
    "            \n",
    "            if n_opt_2019 == 0 or n_opt_2020 == 0 or n_sar_2019 == 0 or n_sar_2020 == 0:\n",
    "                continue\n",
    "\n",
    "            opt_2019 = opt_2019.sort('dateDist').first()\n",
    "            \n",
    "            opt_2020 = opt_2020.sort('dateDist').first()\n",
    "            \n",
    "            sar_2019 = sar_2019.sort('dateDist').first()\n",
    "            sar_2020 = sar_2020.sort('dateDist').first()\n",
    "\n",
    "\n",
    "            feat['properties']['opt_2019'] = opt_2019.getInfo()['id']\n",
    "            feat['properties']['opt_2020'] = opt_2020.getInfo()['id']\n",
    "            feat['properties']['sar_2019'] = sar_2019.getInfo()['id']\n",
    "            feat['properties']['sar_2020'] = sar_2020.getInfo()['id']\n",
    "            feat['properties']['crs'] = opt_2019.getInfo()['bands'][1]['crs']\n",
    "            \n",
    "            dest.write(feat)\n",
    "            \n",
    "            meta_opt_2019 = os.path.join(meta_path, f'{feat_id}_opt_2019.txt')\n",
    "            meta_opt_2020 = os.path.join(meta_path, f'{feat_id}_opt_2020.txt')\n",
    "            meta_sar_2019 = os.path.join(meta_path, f'{feat_id}_sar_2019.txt')\n",
    "            meta_sar_2020 = os.path.join(meta_path, f'{feat_id}_sar_2020.txt')\n",
    "            \n",
    "            save_json(opt_2019.getInfo(), meta_opt_2019)\n",
    "            save_json(opt_2020.getInfo(), meta_opt_2020)\n",
    "            save_json(sar_2019.getInfo(), meta_sar_2019)\n",
    "            save_json(sar_2020.getInfo(), meta_sar_2020)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f90fad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
